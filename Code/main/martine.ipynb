{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9489357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from functions.make_dataset import *\n",
    "from functions.nn_pytorch import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5879b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Martine Pedersen/Oppgaver/Project_3_FYSSTK/kagglehub/datasets/nikhil7280/weather-type-classification/versions/1/weather_classification_data.csv'\n",
    "dataset = WeatherDataset(csv_file=path)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "    \n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af07f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WeatherNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_hidden_layers: int,\n",
    "        output_dim: int,\n",
    "        activation: str = \"relu\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Choose activation function\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"lrelu\": nn.LeakyReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "        }\n",
    "        act = activations[activation.lower()]\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(act)\n",
    "        \n",
    "        # Hidden layers\n",
    "        for h in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(act)\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        layers.append(nn.Softmax())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_model(self, train_loader, eta=1e-2, epochs=10):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=eta)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            for X, y in train_loader:\n",
    "                logits = self(X)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            #print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "    \n",
    "        \n",
    "    def evaluate(self, loader):\n",
    "        self.eval()  # set model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # no gradient computation\n",
    "            for X, y in loader:\n",
    "                logits = self(X)                  # forward pass\n",
    "                preds = logits.argmax(dim=1)     # predicted class\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        return correct / total  # overall accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "input_dim = dataset.X.shape[1]  # number of features\n",
    "hidden = 64\n",
    "num_classes = len(dataset.encoders[\"Weather Type\"].classes_)\n",
    "\n",
    "model = WeatherNN(input_dim=input_dim, hidden_dim=hidden, num_hidden_layers=10, output_dim=num_classes, activation=\"relu\")\n",
    "cost_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc31bb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.2545454545454545\n"
     ]
    }
   ],
   "source": [
    "model.train_model(train_loader, epochs=epochs)\n",
    "\n",
    "accuracy = model.evaluate(test_loader)\n",
    "print(\"Test accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6403a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 9.3643e-27, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.3351e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.9643e-18, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0347e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.6222e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.5451e-21, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.1405e-27, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3473e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.9493e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.3691e-23, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.8193e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4504e-23, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.9382e-16, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.2421e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6634e-26, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.9135e-27, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.5045e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.6094e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6750e-23, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.7620e-25, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4380e-26, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0163e-26, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9764e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.2434e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1519e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.8614e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.2327e-16, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.4772e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0890e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0043e-21, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.8035e-26, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0083e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.0252e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.7955e-23, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.5974e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.6017e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.5094e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.7804e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.6821e-19, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.8104e-21, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.8296e-16, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.7949e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.2575e-28, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.1345e-22, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.9770e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.7208e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0564e-27, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1822e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9556e-25, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.9755e-21, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0077e-18, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0157e-20, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.7701e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.9717e-26, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.1174e-28, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.2871e-24, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.8789e-18, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.3447e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.3118e-17, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.6407e-18, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.5648e-27, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.6258e-26, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.7337e-27, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.6361e-24, 1.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example: take one batch from the test_loader\n",
    "X_batch, y_batch = next(iter(test_loader))\n",
    "\n",
    "logits = model(X_batch)  # forward pass\n",
    "print(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c981f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "preds = logits.argmax(dim=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c905fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels: tensor([3, 0, 2, 3, 1, 3, 3, 1, 1, 0])\n",
      "Predicted labels: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"True labels:\", y_batch[:10])\n",
    "print(\"Predicted labels:\", preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4828d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(logits.sum(dim=1))  # should all be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53204702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
