{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6679bb3",
   "metadata": {},
   "source": [
    "# Project 3 - FYS-STK4155\n",
    "## Neural network using PyTorch and application to weather classification\n",
    "\n",
    "This notebook contains the code which produces the results for the Project 3 report in FYS-STK4155 regarding PyTorch application on building a Neural Network which handles weather type classification.\n",
    "\n",
    "The dataset used was retrieved from: https://www.kaggle.com/datasets/nikhil7280/weather-type-classification/data, 17.11.25.\n",
    "\n",
    "*Fall 2025*\n",
    "\n",
    "**Authors:** Martine Jenssen Pedersen, Sverre Manu Johansen & Kjersti Stangeland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba1493",
   "metadata": {},
   "source": [
    "# To do:\n",
    "* se om pytorch splitter likt som sklearm\n",
    "* legge in skalering i pytroch nn, eller make data.py?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417286a",
   "metadata": {},
   "source": [
    "### Comparing a PyTorch neural network with out own FFNN\n",
    "\n",
    "**We will do numerical experiments and check model performances based on***\n",
    "* Model architectures (# layers, # nodes)\n",
    "* Activation functions\n",
    "    * relu\n",
    "    * lrelu\n",
    "    * sigmoid\n",
    "* Learning rates\n",
    "* Number of epochs\n",
    "\n",
    "**In this notebook will use**\n",
    "* Adam optimizer because we found that was best in Project 2.\n",
    "* Our own built FFNN from Project 2.\n",
    "* A NN built with PyTorch.\n",
    "* Accuracy score to determine how well the networks do classification, using CrossEntropy as metric.\n",
    "* Visualize results using heatmaps.\n",
    "\n",
    "**In other notebooks you'll find**\n",
    "* Similar experiments done with our own built logistic regression model using Scikitlearn, our own FFNN with one layer, and our PyTorch NN with one layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e1bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from functions.make_dataset import *\n",
    "from functions.nn_pytorch import *\n",
    "from functions.ffnn import *\n",
    "from functions.activation_funcs import *\n",
    "from functions.cost_functions import *\n",
    "\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "mplstyle.use([\"ggplot\", \"fast\"])\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.3)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e41cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x163649230>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "# Same seed as project 1 & 2\n",
    "seed = 2018\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b66f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Weather Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>73</td>\n",
       "      <td>9.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>1010.82</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.5</td>\n",
       "      <td>inland</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>96</td>\n",
       "      <td>8.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>1011.43</td>\n",
       "      <td>7</td>\n",
       "      <td>Spring</td>\n",
       "      <td>10.0</td>\n",
       "      <td>inland</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>64</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1018.72</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>5.5</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>83</td>\n",
       "      <td>1.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1026.25</td>\n",
       "      <td>7</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>coastal</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>74</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>990.67</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.5</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Wind Speed  Precipitation (%)    Cloud Cover  \\\n",
       "0         14.0        73         9.5               82.0  partly cloudy   \n",
       "1         39.0        96         8.5               71.0  partly cloudy   \n",
       "2         30.0        64         7.0               16.0          clear   \n",
       "3         38.0        83         1.5               82.0          clear   \n",
       "4         27.0        74        17.0               66.0       overcast   \n",
       "\n",
       "   Atmospheric Pressure  UV Index  Season  Visibility (km)  Location  \\\n",
       "0               1010.82         2  Winter              3.5    inland   \n",
       "1               1011.43         7  Spring             10.0    inland   \n",
       "2               1018.72         5  Spring              5.5  mountain   \n",
       "3               1026.25         7  Spring              1.0   coastal   \n",
       "4                990.67         1  Winter              2.5  mountain   \n",
       "\n",
       "  Weather Type  \n",
       "0        Rainy  \n",
       "1       Cloudy  \n",
       "2        Sunny  \n",
       "3        Sunny  \n",
       "4        Rainy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/kjesta/Desktop/Masteremner/FYS-STK4155/Project_3_FYSSTK/kagglehub/datasets/nikhil7280/weather-type-classification/versions/1/weather_classification_data.csv'\n",
    "\n",
    "ds = pd.read_csv(path)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91badb3",
   "metadata": {},
   "source": [
    "To make the dataset work with PyTorch, we convert features which are categorical (strings) to numerical values. This is done inside `make_dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rainy', 'Cloudy', 'Sunny', 'Snowy'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['Weather Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa83020",
   "metadata": {},
   "source": [
    "# Weather type classification using a PyTorch neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4386b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = WeatherDataset(csv_file=path)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "input_dim = dataset.X.shape[1]  # number of features\n",
    "num_classes = len(dataset.encoders[\"Weather Type\"].classes_)  # number of classes\n",
    "\n",
    "# Load the data \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f04a3",
   "metadata": {},
   "source": [
    "### 1) Exploring different network architectures for different activation functions\n",
    "\n",
    "We start by training our network using different network constructions in terms of number of hidden layers and number of nodes per layer. This is done for three different activation functions, ReLU, LReLU and sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4313939",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "activations = ['relu', 'lrelu', 'sigmoid']\n",
    "\n",
    "num_hidden_layers = [2, 3, 4]\n",
    "num_of_nodes = [16, 32, 64]\n",
    "\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for activation in activations:\n",
    "    for hidden in num_hidden_layers:\n",
    "        for nodes in num_of_nodes:\n",
    "            \n",
    "            # Make a model for a given set of hyperparameters\n",
    "            model = WeatherNN(input_dim=input_dim, hidden_dim=nodes, num_hidden_layers=hidden, output_dim=num_classes, activation=activation)\n",
    "\n",
    "            # Train the model\n",
    "            training_model = model.train_model(train_loader, learning_rate, epochs)\n",
    "\n",
    "            # Evalute accuracy of model\n",
    "            accuracy_train = model.evaluate(train_loader)\n",
    "            accuracy_test  = model.evaluate(test_loader)\n",
    "\n",
    "            print(f'Activation: {activation}, Hidden Layers: {hidden}, Nodes: {nodes}, Test Accuracy: {accuracy_test:.4f}')\n",
    "\n",
    "            results.append({\n",
    "                'Activation': activation,\n",
    "                'Hidden Layers': hidden,\n",
    "                'Nodes': nodes,\n",
    "                'Accuracy_train': accuracy_train,\n",
    "                'Accuracy_test': accuracy_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87975f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_torch_arch = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30840d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 11})\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
    "\n",
    "    fig.suptitle(f'Accuracy Heatmaps for PyTorch NN \\n Activation Function: {activation}', y = 1.1, fontsize=16)\n",
    "\n",
    "    pivot_table_test = results_torch_arch[results_torch_arch['Activation'] == activation].pivot_table(\n",
    "        index=\"Hidden Layers\", columns=\"Nodes\", values=\"Accuracy_test\", aggfunc=\"mean\")\n",
    "    \n",
    "    pivot_table_train = results_torch_arch[results_torch_arch['Activation'] == activation].pivot_table(\n",
    "        index=\"Hidden Layers\", columns=\"Nodes\", values=\"Accuracy_train\", aggfunc=\"mean\")\n",
    "\n",
    "    # Shared vmin/vmax across both heatmaps\n",
    "    vmin = min(pivot_table_test.min().min(), pivot_table_train.min().min())\n",
    "    vmax = max(pivot_table_test.max().max(), pivot_table_train.max().max())\n",
    "\n",
    "    im1 = sns.heatmap(pivot_table_test, annot=True, fmt=\".4f\", cmap=\"YlGnBu\", ax=ax[0], vmin=vmin, vmax=vmax, cbar=False)\n",
    "    ax[0].set_title(f'Test Accuracy')\n",
    "    ax[0].set_xlabel('Nodes per Layer')\n",
    "    ax[0].set_ylabel('Hidden Layers')\n",
    "\n",
    "    im2 = sns.heatmap(pivot_table_train, annot=True, fmt=\".4f\", cmap=\"YlGnBu\", ax=ax[1], vmin=vmin, vmax=vmax, cbar=False)\n",
    "    ax[1].set_title(f'Train Accuracy')\n",
    "    ax[1].set_xlabel('Nodes per Layer')\n",
    "    ax[1].set_ylabel('Hidden Layers')\n",
    "\n",
    "    cbar = fig.colorbar(im2.get_children()[0], ax=ax, orientation=\"horizontal\", pad=0.2, fraction=0.1)\n",
    "    cbar.set_label('Accuracy')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc001164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fidning the best architecture per activation function\n",
    "best_torch_model_arch = results_torch_arch.loc[results_torch_arch.groupby('Activation')['Accuracy_test'].idxmax()]\n",
    "best_torch_model_arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4140b63",
   "metadata": {},
   "source": [
    "### 2) Assessing the impact of learning rate and epoch size on accuracy\n",
    "\n",
    "Here we inherit the best architectures found for each activation function, and explore how different learning rates and number of epochs affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ea044",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 0.5]\n",
    "epoch_options = [10, 50, 100]\n",
    "activations = ['relu', 'lrelu', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for activation in activations:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_options:\n",
    "\n",
    "            # Get the best architecture for the given activation function\n",
    "            num_hidden_layers = int(best_torch_model_arch[best_torch_model_arch['Activation'] == activation]['Hidden Layers'])\n",
    "            num_of_nodes = int(best_torch_model_arch[best_torch_model_arch['Activation'] == activation]['Nodes'])\n",
    "\n",
    "            # Make a model for a given set of hyperparameters\n",
    "            model = WeatherNN(input_dim=input_dim, hidden_dim=num_of_nodes, num_hidden_layers=num_hidden_layers, output_dim=num_classes, activation=activation)\n",
    "\n",
    "            # Train the model\n",
    "            training_model = model.train_model(train_loader, lr, epochs)\n",
    "\n",
    "            # Evalute accuracy of model\n",
    "            accuracy_train = model.evaluate(train_loader)\n",
    "            accuracy_test  = model.evaluate(test_loader)\n",
    "\n",
    "            print(f'Activation: {activation}, Learning rate: {lr}, Number of epochs: {epochs}, Test Accuracy: {accuracy_test:.4f}')\n",
    "\n",
    "            results.append({\n",
    "                'Activation': activation,\n",
    "                'Learning Rate': lr,\n",
    "                'Epochs': epochs,\n",
    "                'Accuracy_train': accuracy_train,\n",
    "                'Accuracy_test': accuracy_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_torch_lrs = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1daa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 11})\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
    "\n",
    "    fig.suptitle(f'Accuracy Heatmaps for PyTorch NN \\n Activation Function: {activation}', y = 1.1, fontsize=16)\n",
    "\n",
    "    pivot_table_test = results_torch_lrs[results_torch_lrs['Activation'] == activation].pivot_table(\n",
    "        index=\"Learning Rate\", columns=\"Epochs\", values=\"Accuracy_test\", aggfunc=\"mean\")\n",
    "    \n",
    "    pivot_table_train = results_torch_lrs[results_torch_lrs['Activation'] == activation].pivot_table(\n",
    "        index=\"Learning Rate\", columns=\"Epochs\", values=\"Accuracy_train\", aggfunc=\"mean\")\n",
    "\n",
    "    # Shared vmin/vmax across both heatmaps\n",
    "    vmin = min(pivot_table_test.min().min(), pivot_table_train.min().min())\n",
    "    vmax = max(pivot_table_test.max().max(), pivot_table_train.max().max())\n",
    "\n",
    "    im1 = sns.heatmap(pivot_table_test, annot=True, fmt=\".4f\", cmap=\"YlGnBu\", ax=ax[0], vmin=vmin, vmax=vmax, cbar=False)\n",
    "    ax[0].set_title(f'Test Accuracy')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Learning Rate')\n",
    "\n",
    "    im2 = sns.heatmap(pivot_table_train, annot=True, fmt=\".4f\", cmap=\"YlGnBu\", ax=ax[1], vmin=vmin, vmax=vmax, cbar=False)\n",
    "    ax[1].set_title(f'Train Accuracy')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Learning Rate')\n",
    "\n",
    "    cbar = fig.colorbar(im2.get_children()[0], ax=ax, orientation=\"horizontal\", pad=0.2, fraction=0.1)\n",
    "    cbar.set_label('Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a39a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_torch_lrs = results_torch_lrs.loc[results_torch_lrs.groupby('Activation')['Accuracy_test'].idxmax()]\n",
    "best_model_torch_lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76f436",
   "metadata": {},
   "source": [
    "### 3) Adding L1 and L2 regularization\n",
    "\n",
    "Lastly, we train our PyTorch network with the best found acrhitecutre per activation and the best learning rate and epochs (for each activation respectively), but add regularization terms to penalize weights and help mitigate overfitting. We find this interesting to test as we know there are outliers in our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d799a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f7734",
   "metadata": {},
   "source": [
    "# Weather type classification using our own NN\n",
    "\n",
    "We now repeat the same analysis done for our PyTorch network on our own FFNN code from Project 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae78ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Create label encoders for each categorical column\n",
    "encoders = {col: LabelEncoder() for col in cat_cols}\n",
    "\n",
    "# Apply encoding\n",
    "# String to numerical conversion\n",
    "for col in cat_cols:\n",
    "    data[col] = encoders[col].fit_transform(data[col]).astype(int)\n",
    "\n",
    "X = data.drop('Weather Type', axis=1).values\n",
    "y = data['Weather Type'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "targets = np.zeros((len(y), 4))\n",
    "for i, val in enumerate(y):\n",
    "    targets[i, val] = 1\n",
    "y = targets\n",
    "\n",
    "# Spltit the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3280f3d",
   "metadata": {},
   "source": [
    "### 1) Exploring different network architectures for different activation functions\n",
    "\n",
    "We start by training our network using different network constructions in terms of number of hidden layers and number of nodes per layer. This is done for three different activation functions, ReLU, LReLU and sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "activations = [RELU, LRELU, sigmoid]\n",
    "activation_names = ['relu', 'lrelu', 'sigmoid']\n",
    "\n",
    "num_hidden_layers = [2, 3, 4]\n",
    "num_of_nodes = [16, 32, 64]\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce50ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ffnn_classification(y_pred, y_true):\n",
    "    pred_class = np.argmax(y_pred, axis=1)\n",
    "    true_class = np.argmax(y_true, axis=1)\n",
    "\n",
    "    return np.mean(pred_class == true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for activation, activation_name in zip(activations, activation_names):\n",
    "    for hidden in num_hidden_layers:\n",
    "        for nodes in num_of_nodes:\n",
    "\n",
    "            # Make lists of activation functions and their derivatives\n",
    "            # Output layer uses softmax activation\n",
    "            activation_funcs = [activation] * hidden + [softmax]\n",
    "            activation_ders  = [derivate(activation)] * hidden + [derivate(softmax)]\n",
    "            \n",
    "            # Make a model for a given set of hyperparameters\n",
    "            model = NeuralNetwork(\n",
    "            network_input_size=X_train.shape[1],\n",
    "            layer_output_sizes=[nodes] * hidden + [4],\n",
    "            activation_funcs=activation_funcs,\n",
    "            activation_ders=activation_ders,\n",
    "            cost_fun=cross_entropy,\n",
    "            cost_der=cross_entropy_der)\n",
    "\n",
    "            # Train network with stochastic gradient descent and Adam optimizer\n",
    "            model.train_SGD(X_train, y_train, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size, optimizer='adam')\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred_test = model._feed_forward(X_test)\n",
    "            y_pred_train = model._feed_forward(X_train)\n",
    "\n",
    "            # Compute accuracy\n",
    "            accuracy_train = evaluate_ffnn_classification(y_pred_train, y_train)\n",
    "            accuracy_test  = evaluate_ffnn_classification(y_pred_test, y_test)\n",
    "\n",
    "            print(f'Activation: {activation_name}, Hidden Layers: {hidden}, Nodes: {nodes}, Test Accuracy: {accuracy_test:.4f}')\n",
    "\n",
    "            results.append({\n",
    "                'Activation': activation_name,\n",
    "                'Hidden Layers': hidden,\n",
    "                'Nodes': nodes,\n",
    "                'Accuracy_train': accuracy_train,\n",
    "                'Accuracy_test': accuracy_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ffnn_arch = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 11})\n",
    "\n",
    "for activation, activation_name in zip(activations, activation_names):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
    "\n",
    "    fig.suptitle(f'Accuracy Heatmaps for FFNN \\n Activation Function: {activation_name}', y = 1.1, fontsize=16)\n",
    "    pivot_table_test = results_ffnn_arch[results_ffnn_arch['Activation'] == activation_name].pivot_table(\n",
    "        index=\"Hidden Layers\", columns=\"Nodes\", values=\"Accuracy_test\", aggfunc=\"mean\")\n",
    "    \n",
    "    pivot_table_train = results_ffnn_arch[results_ffnn_arch['Activation'] == activation_name].pivot_table(\n",
    "        index=\"Hidden Layers\", columns=\"Nodes\", values=\"Accuracy_train\", aggfunc=\"mean\")\n",
    "\n",
    "    # Shared vmin/vmax across both heatmaps\n",
    "    vmin = min(pivot_table_test.min().min(), pivot_table_train.min().min())\n",
    "    vmax = max(pivot_table_test.max().max(), pivot_table_train.max().max())\n",
    "\n",
    "    im1 = sns.heatmap(pivot_table_test, annot=True, fmt=\".4f\", cmap=\"YlGnBu\", ax=ax[0], vmin=vmin, vmax=vmax, cbar=False)\n",
    "    ax[0].set_title(f'Test Accuracy')\n",
    "    ax[0].set_xlabel('Nodes per Layer')\n",
    "    ax[0].set_ylabel('Hidden Layers')\n",
    "\n",
    "    im2 = sns.heatmap(pivot_table_train, annot=True, fmt=\".4f\", cmap=\"YlGnBu\", ax=ax[1], vmin=vmin, vmax=vmax, cbar=False)\n",
    "    ax[1].set_title(f'Train Accuracy')\n",
    "    ax[1].set_xlabel('Nodes per Layer')\n",
    "    ax[1].set_ylabel('Hidden Layers')\n",
    "\n",
    "    cbar = fig.colorbar(im2.get_children()[0], ax=ax, orientation=\"horizontal\", pad=0.2, fraction=0.1)\n",
    "    cbar.set_label('Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae19983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07aa1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
